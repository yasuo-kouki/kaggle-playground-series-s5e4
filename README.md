# kaggle-playground-series-s5e4

データの特徴を軽く調べたが，欠損値や異常値は特に見られなかった
そのため，特徴量は特に加えずにxgboostモデルでの学習をした．
学習の結果はMSE	RMSE	R2はそれぞれ0.003165	0.043659	0.885364になり，そこそこ良い制度がでた
そのため，kaggleに提出をした．結果はスコア: 0.05569であり，順位は1173/2024であった．
1位の評価は0.05537であり，ほとんどの記録が拮抗していることがわかった．

そのため，次は特徴量の作成を試みる
データの相関関係の特徴量マップからカーブと事故件数に0.15と少しの相関が見られた．それ以外は相関が0に近く有効性が見えなかったため除外した
そのため，特徴量としてモデルに追加した．その結果，学習結果が少しだけ上がり，特徴量としての有効性も特徴量の重みから見えたため，kaggleに提出をした．その結果スコア:0.05564であり，順位は991/2028と改善が少し見られた．

アンサンブル学習をする前にkaggleの議論のページから知識を得ることにした．
誤差プロットから高い値を予測するときに低めに予測している情報を知り，実際に自分でも確認をしてみたが，その通りであった．そのため，高リスク領域のデータを増やしたり，特徴量の追加が必要であることを学んだ．
残留誤差のヒストグラムの平均の値は-0.00018なので正常に近い
Q-Qプロットで残差の分布が正規分布に従うかを確認では，極端な値が正規分布より多いことがわかり，はずれ値が多いことが読み取れた．
これらの結果から，はずれ値の処理と，事故を起こしやすい特徴量を探すことが重要であることがわかった．
異常値が多いため，異常値に強いロバストスケーリングを行い提出したが，スコアが前回と変わらず，0.05564であった．原因は残留誤差プロットを確認すると前回の提出時のプロットとほぼかわっていなかったためである．
そのため，次の提出時にはプロットの異常値がなくなったことを確認してから行うこととする．

ディープランニングモデルの作成を作成した．
MSE	MAE	R2
0	0.00326	0.044277	0.881932の精度が出たため，提出をした．
その結果0.05650であり，xgboostモデルより低い結果となった

上記の2つのモデルからハイブリッドモデルの作成を行った．重みの最適化をして実装し，その結果をkaggleに上げたが，評価は0.05566となった．

特徴量の追加をしたがイマイチ改善は見られなかった．
ディープランニングのone-hotではなく，ラベルエンコードになっていたため，修正した．
しかし，性能の改善は見れなかった．

モデルにロバスト回帰などの異常値に強くしたが改善は見られなかった．
そのため，新たにlgbモデルの作成をした．lgbモデルは異常値に強いため，改善が見られると思ったが，lgbモデルで特徴量なしの時の評価が，0.05568であり，特徴量を追加したモデルは0.05570となった．これはxgbモデルの評価に追加ものになっており，新たな特徴を掴めて可能性があるため，ハイブリットモデルでの評価をみることにした．
その結果評価がスコア: 0.05558となり，最も高い評価となった．634/2284となり，改善が見られた．しかし，最適化学習の結果ディープランニングモデルの重みが0になっていたことから，ディープランニングの結果は好ましくないことがわかった．

機械学習の成績がいいことからランダムホレストモデルの導入をした．